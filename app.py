# collection/app.py ‚Äî Multi-domain preference collection UI
# Run: pip install gradio pandas

import gradio as gr
import json
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Optional
import hashlib
import random
import sys

# Add parent to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from domains.taxonomy import DomainID, DOMAINS, get_quality_rubric
from domains.prompt_generator import DomainPromptGenerator, SEED_PROMPTS


class PreferenceStore:
    """Manages preference data storage with audit trail."""
    
    def __init__(self, base_path: str = None):
        if base_path is None:
            base_path = Path(__file__).parent.parent / "preference_data"
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
    
    def _get_domain_file(self, domain_id: str) -> Path:
        return self.base_path / f"{domain_id}_preferences.jsonl"
    
    def save(self, record: dict) -> str:
        """Save a preference record with integrity hash."""
        record["timestamp"] = datetime.utcnow().isoformat()
        record["record_hash"] = hashlib.sha256(
            json.dumps(record, sort_keys=True).encode()
        ).hexdigest()[:16]
        
        filepath = self._get_domain_file(record["domain"])
        with open(filepath, "a") as f:
            f.write(json.dumps(record) + "\n")
        
        return record["record_hash"]
    
    def get_stats(self, domain_id: str = None) -> dict:
        """Get collection statistics."""
        stats = {}
        if domain_id:
            files = [self._get_domain_file(domain_id)]
        else:
            files = list(self.base_path.glob("*_preferences.jsonl"))
        
        for f in files:
            if f.exists():
                domain = f.stem.replace("_preferences", "")
                count = sum(1 for _ in open(f))
                stats[domain] = count
        
        return stats
    
    def export_for_training(self, domain_id: str, format: str = "dpo") -> pd.DataFrame:
        """Export data in training-ready format."""
        filepath = self._get_domain_file(domain_id)
        if not filepath.exists():
            return pd.DataFrame()
        
        records = [json.loads(line) for line in open(filepath)]
        
        if format == "dpo":
            # Direct Preference Optimization format
            data = []
            for r in records:
                if r.get("preference") in ["A", "B"]:
                    chosen = r["response_a"] if r["preference"] == "A" else r["response_b"]
                    rejected = r["response_b"] if r["preference"] == "A" else r["response_a"]
                    data.append({
                        "prompt": r["prompt"],
                        "chosen": chosen,
                        "rejected": rejected,
                        "domain": r["domain"],
                        "category": r.get("category", "unknown")
                    })
            return pd.DataFrame(data)
        
        return pd.DataFrame(records)


class CollectionApp:
    """Multi-domain preference collection application."""
    
    def __init__(self):
        self.store = PreferenceStore()
        self.current_pair = None
        self.generators = {
            domain_id: DomainPromptGenerator(domain_id) 
            for domain_id in DomainID
        }
    
    def get_next_pair(self, domain: str, category: str = None) -> tuple:
        """Get next prompt and response pair for annotation."""
        domain_id = DomainID(domain)
        generator = self.generators[domain_id]
        
        # Get prompt
        prompt_data = generator.get_random_prompt(category if category != "all" else None)
        prompt = prompt_data["prompt"]
        
        # For demo, generate placeholder responses
        # In production, call your generator model (Ollama, API, etc.)
        response_a = f"""[Response A]

This is a placeholder response for the prompt. In production, this would be generated by your LLM (e.g., Ollama llama3.1:8b).

The response would address: {prompt[:100]}...

To enable real generation:
1. Set up Ollama: `ollama serve && ollama pull llama3.1:8b`
2. Uncomment the generation code in this file
3. Responses will be generated with different temperatures for quality variance"""

        response_b = f"""[Response B]

This is an alternative placeholder response. In production, this would be generated with higher temperature (0.9) to create natural quality variance.

The response addresses: {prompt[:100]}...

Quality differences emerge from:
- Temperature variation (0.3 vs 0.9)
- Token limits (1024 vs 512)
- Different model checkpoints"""

        self.current_pair = {
            "domain": domain,
            "category": prompt_data.get("category", "unknown"),
            "prompt": prompt,
            "response_a": response_a,
            "response_b": response_b
        }
        
        return prompt, response_a, response_b
    
    def submit_preference(self, 
                          annotator_id: str,
                          preference: str,
                          dimension_scores: dict,
                          notes: str) -> str:
        """Submit a preference annotation."""
        if not self.current_pair:
            return "‚ùå No active pair. Load a new pair first."
        
        if not annotator_id:
            return "‚ùå Please enter your annotator ID."
        
        if not preference:
            return "‚ùå Please select a preference (A, B, tie, or both_bad)."
        
        record = {
            **self.current_pair,
            "annotator_id": annotator_id,
            "preference": preference,
            "dimension_scores": dimension_scores,
            "notes": notes
        }
        
        record_hash = self.store.save(record)
        stats = self.store.get_stats(self.current_pair["domain"])
        
        return f"‚úì Saved [{record_hash}]. Domain total: {stats.get(self.current_pair['domain'], 0)}"
    
    def get_rubric(self, domain: str) -> str:
        """Get the quality rubric for a domain."""
        try:
            domain_id = DomainID(domain)
            return get_quality_rubric(domain_id)
        except ValueError:
            return "Invalid domain"


def create_ui():
    """Create the Gradio UI."""
    app = CollectionApp()
    
    domain_choices = [(d.name.replace("_", " ").title(), d.value) for d in DomainID]
    
    with gr.Blocks(title="Zuup Preference Collection", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# üéØ Zuup Domain-Specific Preference Collection")
        gr.Markdown("Collect human preferences for training domain-expert AI systems.")
        
        with gr.Row():
            with gr.Column(scale=1):
                annotator_id = gr.Textbox(
                    label="Annotator ID", 
                    placeholder="your_name",
                    info="Your unique identifier for tracking"
                )
                domain_select = gr.Dropdown(
                    choices=domain_choices,
                    label="Domain",
                    value="procurement"
                )
                category_select = gr.Dropdown(
                    choices=["all"],
                    label="Category",
                    value="all"
                )
                load_btn = gr.Button("üîÑ Load New Pair", variant="primary")
                
            with gr.Column(scale=3):
                stats_display = gr.Markdown("*Click 'Load New Pair' to start*")
        
        with gr.Row():
            with gr.Column():
                prompt_display = gr.Textbox(
                    label="üìù Prompt",
                    lines=4,
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                response_a = gr.Textbox(
                    label="Response A",
                    lines=12,
                    interactive=False
                )
            with gr.Column():
                response_b = gr.Textbox(
                    label="Response B", 
                    lines=12,
                    interactive=False
                )
        
        gr.Markdown("### ‚öñÔ∏è Evaluation")
        
        with gr.Row():
            with gr.Column():
                preference = gr.Radio(
                    choices=["A", "B", "tie", "both_bad"],
                    label="Which response is better?",
                    info="Select the better response or indicate a tie/both bad"
                )
            with gr.Column():
                # Dimension scoring
                dim_accuracy = gr.Slider(1, 5, step=1, label="Accuracy/Correctness", value=3)
                dim_safety = gr.Slider(1, 5, step=1, label="Safety/Compliance", value=3)
                dim_actionability = gr.Slider(1, 5, step=1, label="Actionability", value=3)
                dim_clarity = gr.Slider(1, 5, step=1, label="Clarity", value=3)
        
        notes = gr.Textbox(
            label="Notes (optional)",
            placeholder="Any observations about quality differences...",
            lines=2
        )
        
        with gr.Row():
            submit_btn = gr.Button("‚úÖ Submit Preference", variant="primary", size="lg")
            skip_btn = gr.Button("‚è≠Ô∏è Skip (Low Quality Pair)", variant="secondary")
        
        output = gr.Textbox(label="Status", interactive=False)
        
        with gr.Accordion("üìã Quality Rubric (click to expand)", open=False):
            rubric_display = gr.Markdown()
        
        # Update categories when domain changes
        def update_categories(domain):
            try:
                domain_id = DomainID(domain)
                if domain_id in SEED_PROMPTS:
                    cats = list(SEED_PROMPTS[domain_id].keys())
                    return gr.Dropdown(choices=["all"] + cats, value="all")
            except:
                pass
            return gr.Dropdown(choices=["all"], value="all")
        
        domain_select.change(
            update_categories,
            inputs=[domain_select],
            outputs=[category_select]
        )
        
        # Load new pair
        def load_pair(domain, category):
            prompt, resp_a, resp_b = app.get_next_pair(domain, category)
            stats = app.store.get_stats()
            if stats:
                stats_md = "**üìä Collection Stats:** " + ", ".join([f"{k}: {v}" for k, v in stats.items()])
            else:
                stats_md = "**üìä Collection Stats:** No data yet"
            rubric = app.get_rubric(domain)
            return prompt, resp_a, resp_b, stats_md, rubric
        
        load_btn.click(
            load_pair,
            inputs=[domain_select, category_select],
            outputs=[prompt_display, response_a, response_b, stats_display, rubric_display]
        )
        
        # Submit preference
        def submit(annotator, pref, acc, safety, action, clarity, notes_text):
            dims = {
                "accuracy": acc,
                "safety": safety,
                "actionability": action,
                "clarity": clarity
            }
            return app.submit_preference(annotator, pref, dims, notes_text)
        
        submit_btn.click(
            submit,
            inputs=[annotator_id, preference, dim_accuracy, dim_safety, dim_actionability, dim_clarity, notes],
            outputs=[output]
        )
        
        # Skip
        def skip(annotator):
            if app.current_pair:
                record = {
                    **app.current_pair,
                    "annotator_id": annotator or "anonymous",
                    "preference": "skipped",
                    "skip_reason": "low_quality_pair"
                }
                app.store.save(record)
                return "‚è≠Ô∏è Skipped and logged."
            return "No pair to skip."
        
        skip_btn.click(skip, inputs=[annotator_id], outputs=[output])
    
    return demo


if __name__ == "__main__":
    print("=" * 50)
    print("üéØ Zuup Preference Collection")
    print("=" * 50)
    print("\nStarting Gradio server...")
    print("Local URL:  http://127.0.0.1:7860")
    print("Share URL:  Will be generated below\n")
    
    demo = create_ui()
    demo.launch(
        share=True,  # Creates public URL for annotators
        server_name="0.0.0.0",
        server_port=7860
    )
